server:
  port: 8081

spring:
  application:
    name: llm-orchestrator
resilience4j:
  circuitbreaker:
    instances:
      openai:
        slidingWindowSize: 10
        minimumNumberOfCalls: 5
        failureRateThreshold: 50
        waitDurationInOpenState: 10s
      gemini:
        slidingWindowSize: 10
        minimumNumberOfCalls: 5
        failureRateThreshold: 50
        waitDurationInOpenState: 10s

  retry:
    instances:
      openai:
        maxAttempts: 2
        waitDuration: 500ms
      gemini:
        maxAttempts: 2
        waitDuration: 500ms

#  timelimiter:
#    instances:
#      openai:
#        timeoutDuration: 2s
#      gemini:
#        timeoutDuration: 2s

management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,env,prometheus
  endpoint:
    health:
      show-details: always

llm:
  providers:
    openai:
      base-url: https://api.openai.com
      enabled: true
      mock: false        # keep true for now
      model: gpt-4o-mini
      timeout-ms: 8000
    gemini:
      base-url: http://localhost:9992
      enabled: true
      mock: true
