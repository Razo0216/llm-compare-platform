server:
  port: 8081

spring:
  main:
    allow-bean-definition-overriding: true
  application:
    name: llm-orchestrator
  security:
    oauth2:
      resourceserver:
        jwt:
          issuer-uri: http://localhost:8090/realms/llm-openai-gemini-compare

resilience4j:
  circuitbreaker:
    instances:
      openai:
        slidingWindowSize: 20
        minimumNumberOfCalls: 5
        failureRateThreshold: 50
        waitDurationInOpenState: 300000s
      gemini:
        slidingWindowSize: 20
        minimumNumberOfCalls: 5
        failureRateThreshold: 50
        waitDurationInOpenState: 300000s

  retry:
    instances:
      openai:
        maxAttempts: 2
        waitDuration: 500ms
      gemini:
        maxAttempts: 2
        waitDuration: 500ms

  timelimiter:
    instances:
      openai:
        timeoutDuration: 500s
      gemini:
        timeoutDuration: 500s

management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,env,prometheus
  endpoint:
    health:
      show-details: always

llm:
  providers:
    openai:
      base-url: https://api.openai.com
      enabled: true
      mock: false        # keep true for now
      model: gpt-4o-mini
      timeout-ms: 800000
    gemini:
      base-url: https://generativelanguage.googleapis.com
      enabled: true
      mock: false
      model: gemini-2.5-flash
      timeout-ms: 800000
